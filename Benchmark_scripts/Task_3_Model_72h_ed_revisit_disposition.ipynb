{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling for predicting 72h ED revisit at ED discharge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flow:\n",
    "1. Task-specific filter\n",
    "2. Variable selection\n",
    "3. Modeling script\n",
    "4. Performance output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.models import load_model\n",
    "from helpers import PlotROCCurve, get_lstm_data_gen\n",
    "from dataset_path import output_path\n",
    "\n",
    "path = output_path\n",
    "\n",
    "output_path = os.path.join(path, \"Figure3\")\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "df_train = pd.read_csv((os.path.join(path, 'train.csv')))\n",
    "df_test = pd.read_csv((os.path.join(path, 'test.csv')))\n",
    "confidence_interval = 95\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100) \n",
    "pd.set_option('display.max_rows', 100) \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. task-specific filter: exclude ED death cases for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train['before_ed_mortality'] == False) & (df_train['outcome_hospitalization'] == False) & (df_train['ed_death'] == False)]\n",
    "df_test = df_test[(df_test['before_ed_mortality'] == False) & (df_test['outcome_hospitalization'] == False) & (df_test['ed_death'] == False)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = [\"age\", \"gender\", \n",
    "            \n",
    "            \"n_ed_30d\", \"n_ed_90d\", \"n_ed_365d\", \"n_hosp_30d\", \"n_hosp_90d\", \n",
    "            \"n_hosp_365d\", \"n_icu_30d\", \"n_icu_90d\", \"n_icu_365d\", \n",
    "            \n",
    "            \"triage_pain\", \"triage_acuity\",\n",
    "            \n",
    "            \"chiefcom_chest_pain\", \"chiefcom_abdominal_pain\", \"chiefcom_headache\", \n",
    "            \"chiefcom_shortness_of_breath\", \"chiefcom_back_pain\", \"chiefcom_cough\", \n",
    "            \"chiefcom_nausea_vomiting\", \"chiefcom_fever_chills\", \"chiefcom_syncope\",\n",
    "            \"chiefcom_dizziness\",\n",
    "            \n",
    "            \"cci_MI\", \"cci_CHF\", \"cci_PVD\", \"cci_Stroke\", \"cci_Dementia\", \"cci_Pulmonary\", \n",
    "            \"cci_Rheumatic\", \"cci_PUD\", \"cci_Liver1\", \"cci_DM1\", \"cci_DM2\", \n",
    "            \"cci_Paralysis\", \"cci_Renal\", \"cci_Cancer1\", \"cci_Liver2\", \"cci_Cancer2\", \n",
    "            \"cci_HIV\",\n",
    "            \n",
    "            \"eci_Arrhythmia\", \"eci_Valvular\", \"eci_PHTN\",  \"eci_HTN1\", \"eci_HTN2\",  \n",
    "            \"eci_NeuroOther\", \"eci_Hypothyroid\", \"eci_Lymphoma\", \"eci_Coagulopathy\", \n",
    "            \"eci_Obesity\", \"eci_WeightLoss\", \"eci_FluidsLytes\", \"eci_BloodLoss\", \n",
    "            \"eci_Anemia\", \"eci_Alcohol\", \"eci_Drugs\", \"eci_Psychoses\", \"eci_Depression\",\n",
    "            \n",
    "            \"ed_temperature_last\", \"ed_heartrate_last\", \"ed_resprate_last\", \n",
    "            \"ed_o2sat_last\", \"ed_sbp_last\", \"ed_dbp_last\", \"ed_los\", \"n_med\", \"n_medrecon\"]\n",
    "\n",
    "outcome = \"outcome_ed_revisit_3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[variable].copy()\n",
    "y_train = df_train[outcome].copy()\n",
    "X_test = df_test[variable].copy()\n",
    "y_test = df_test[outcome].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "X_train['gender'] = encoder.fit_transform(X_train['gender'])\n",
    "X_test['gender'] = encoder.transform(X_test['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['ed_los'] = pd.to_timedelta(X_train['ed_los']).dt.seconds / 60\n",
    "X_test['ed_los'] = pd.to_timedelta(X_test['ed_los']).dt.seconds / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('class ratio')\n",
    "ratio = y_train.sum()/(~y_train).sum()\n",
    "print('positive : negative =', ratio, ': 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Modeling script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for all results\n",
    "result_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(random_state=random_seed)\n",
    "start = time.time()\n",
    "logreg.fit(X_train,y_train)\n",
    "runtime = time.time()-start\n",
    "print('Training time:', runtime, 'seconds')\n",
    "probs = logreg.predict_proba(X_test)\n",
    "result = PlotROCCurve(probs[:,1],y_test, ci=confidence_interval, random_seed=random_seed)\n",
    "\n",
    "results = [\"LR\"]\n",
    "results.extend(result)\n",
    "results.append(runtime)\n",
    "result_list.append(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandomForest:\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier(random_state=random_seed)\n",
    "start = time.time()\n",
    "rf.fit(X_train,y_train)\n",
    "runtime = time.time()-start\n",
    "print('Training time:', runtime, 'seconds')\n",
    "probs = rf.predict_proba(X_test)\n",
    "result = PlotROCCurve(probs[:,1],y_test, ci=confidence_interval, random_seed=random_seed)\n",
    "importances = rf.feature_importances_\n",
    "print(importances)\n",
    "\n",
    "results = [\"RF\"]\n",
    "results.extend(result)\n",
    "results.append(runtime)\n",
    "result_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GradientBoosting:\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(random_state=random_seed)\n",
    "start = time.time()\n",
    "gb.fit(X_train, y_train)\n",
    "runtime = time.time()-start\n",
    "print('Training time:', runtime, 'seconds')\n",
    "probs = gb.predict_proba(X_test)\n",
    "result = PlotROCCurve(probs[:,1],y_test, ci=confidence_interval, random_seed=random_seed)\n",
    "\n",
    "results = [\"GB\"]\n",
    "results.extend(result)\n",
    "results.append(runtime)\n",
    "result_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dense_1 = Dense(128, activation='relu')\n",
    "        self.dense_2 = Dense(64, activation='relu')\n",
    "        self.classifier = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell if not retraining\n",
    "mlp = MLP()\n",
    "mlp.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=0.001), \n",
    "              metrics=['accuracy', 'AUC', {'auprc': metrics.AUC(name='auprc', curve='PR')}, \n",
    "                       'TruePositives', 'TrueNegatives', 'Precision', 'Recall'])\n",
    "start = time.time()\n",
    "mlp.fit(X_train.astype(np.float32), y_train, batch_size=200, epochs=20)\n",
    "runtime = time.time() - start\n",
    "print('Training time:', runtime, 'seconds')\n",
    "mlp.save('72h_ed_revisit_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP:\")\n",
    "#mlp = load_model('72h_ed_revisit_mlp')\n",
    "probs = mlp.predict(X_test.astype(np.float32))\n",
    "result = PlotROCCurve(probs,y_test, ci=confidence_interval, random_seed=random_seed)\n",
    "results = [\"MLP\"]\n",
    "results.extend(result)\n",
    "results.append(runtime)\n",
    "result_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data for LSTM\n",
    "resample_freq = '1H' #'30T'\n",
    "df_vitalsign = pd.read_csv(os.path.join(path, 'ed_vitalsign_' + resample_freq + '_resampled.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen, test_data_gen = get_lstm_data_gen(df_train, df_test, df_vitalsign, variable, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LSTM_MLP, self).__init__()\n",
    "        self.dense_1 = Dense(96, activation='relu')\n",
    "        self.lstm = LSTM(32)\n",
    "        self.dense_2 = Dense(64, activation='relu')\n",
    "        self.classifier = Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x1, x2 = x\n",
    "        x = self.dense_1(x1)\n",
    "        lstm_output = self.lstm(x2)\n",
    "        x = concatenate([x, lstm_output])\n",
    "        x = self.dense_2(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell if not retraining\n",
    "lstm = LSTM_MLP()\n",
    "lstm.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=0.001), \n",
    "              metrics=['accuracy', 'AUC', {'auprc': metrics.AUC(name='auprc', curve='PR')}, \n",
    "                       'TruePositives', 'TrueNegatives', 'Precision', 'Recall'])\n",
    "\n",
    "start = time.time()\n",
    "lstm.fit(train_data_gen, batch_size=200, epochs=20)\n",
    "runtime = time.time() - start\n",
    "print('Training time:', runtime, 'seconds')\n",
    "lstm.save('72h_ed_revisit_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LSTM:\")\n",
    "lstm = load_model('72h_ed_revisit_lstm')\n",
    "probs = lstm.predict(test_data_gen)\n",
    "result = PlotROCCurve(probs, y_test, ci=confidence_interval, random_seed=random_seed)\n",
    "results = [\"LSTM\"]\n",
    "results.extend(result)\n",
    "results.append(runtime)\n",
    "result_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_performance(s, random_seed=0):\n",
    "    print(s)\n",
    "    score = np.array(df_test[s])\n",
    "    result = PlotROCCurve(score,y_test, ci=confidence_interval, random_seed=random_seed)\n",
    "    runtime = 0\n",
    "    results = [s]\n",
    "    results.extend(result)\n",
    "    results.append(runtime)\n",
    "    result_list.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input AutoScore result from csv (implemented by R, detail: https://github.com/nliulab/AutoScore)\n",
    "AutoScore_pred = pd.read_csv((os.path.join(path, 'AutoScore_ED_revisit.csv')))\n",
    "df_test[\"AutoScore\"] = AutoScore_pred[\"pred_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score_performance(\"AutoScore\", random_seed=random_seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import optimizers, metrics, layers, Model\n",
    "from embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Med2Vec:\")\n",
    "version = 'v10'\n",
    "batch_size=200\n",
    "vocabulary = vocabulary_map[version]\n",
    "df_icd_encode = pd.read_csv(os.path.join(path, 'icd_list_dataset_'+version+'.csv'))\n",
    "df_train_embed = pd.merge(df_train, df_icd_encode[['stay_id', 'icd_encoded_list']], how='left', on='stay_id')\n",
    "df_test_embed = pd.merge(df_test, df_icd_encode[['stay_id', 'icd_encoded_list']], how='left', on='stay_id')\n",
    "\n",
    "train_gen, test_gen = setup_embedding_data(df_train_embed, df_test_embed, X_train, y_train, X_test, y_test, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train from scratch, set load_model to None\n",
    "load_model = None# \"embedding_revisit_\"+version \n",
    "save_model = \"embedding_revisit_\"+version\n",
    "\n",
    "if load_model:\n",
    "        model = keras.models.load_model(load_model)\n",
    "else:\n",
    "        model = create_embedding_model(vocabulary, len(variable))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', \n",
    "        optimizer=optimizers.Adam(learning_rate=0.001, decay=0.01), \n",
    "        metrics=['accuracy', 'AUC', {'aucpr': metrics.AUC(name='aucpr', curve='PR')}, \n",
    "                    'TruePositives', 'TrueNegatives', 'Precision', 'Recall'])\n",
    "runtime = 1063.299 # to be updated\n",
    "if not load_model:\n",
    "        start = time.time()\n",
    "        model.fit(train_gen, epochs=100, class_weight={1:ratio, 0:1}, verbose=0)\n",
    "        runtime = time.time()-start\n",
    "        print('Training time:', runtime, 'seconds')\n",
    "if save_model:\n",
    "        keras.models.save_model(model, save_model)\n",
    "output = model.predict(test_gen)\n",
    "result = PlotROCCurve(output,y_test, ci=confidence_interval, random_seed=random_seed)\n",
    "\n",
    "results = [\"Med2Vec\"]\n",
    "results.extend(result)\n",
    "results.append(runtime)\n",
    "result_list.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Performance output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_list, columns=['Model', 'auroc', 'ap', 'sensitivity', 'specificity', 'threshold', 'lower_auroc', 'upper_auroc', 'std_auroc', 'lower_ap', 'upper_ap', 'std_ap', 'lower_sensitivity', 'upper_sensitivity', 'std_sensitivity', 'lower_specificity', 'upper_specificity', 'std_specificity', 'runtime'])\n",
    "result_df.to_csv(os.path.join(path, 'result_72h_ed_revivist_disposition.csv'), index=False)\n",
    "result_df = result_df.round(3)\n",
    "formatted_result_df = pd.DataFrame()\n",
    "formatted_result_df[['Model', 'Threshold']] = result_df[['Model', 'threshold']]\n",
    "formatted_result_df['AUROC'] = result_df['auroc'].astype(str) + ' (' + result_df['lower_auroc'].astype(str) + \\\n",
    "                               '-' + result_df['upper_auroc'].astype(str) + ')'\n",
    "formatted_result_df['AUPRC'] = result_df['ap'].astype(str) + ' (' + result_df['lower_ap'].astype(str) + \\\n",
    "                               '-' + result_df['upper_ap'].astype(str) + ')'\n",
    "formatted_result_df['Sensitivity'] = result_df['sensitivity'].astype(str) + ' (' + result_df['lower_sensitivity'].astype(str) + \\\n",
    "                                     '-' + result_df['upper_sensitivity'].astype(str) + ')'\n",
    "formatted_result_df['Specificity'] = result_df['specificity'].astype(str) + ' (' + result_df['lower_specificity'].astype(str) + \\\n",
    "                                     '-' + result_df['upper_specificity'].astype(str) + ')'\n",
    "formatted_result_df[['Runtime']] = result_df[['runtime']]\n",
    "formatted_result_df.to_csv(os.path.join(path, 'task3.csv'), index=False)\n",
    "formatted_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers import plot_confidence_interval\n",
    "plot_confidence_interval(result_df, metric='auroc', ci=confidence_interval, name = \"AUROC\", \n",
    "                         my_file = 'AUROC_72h.eps', my_path = output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confidence_interval(result_df, metric='ap', ci=confidence_interval, name = \"AUPRC\", \n",
    "                         my_file = 'AUPRC_72h.eps', my_path = output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame(zip(variable, importances), columns=['Variable','Importance'])\n",
    "importance_df.to_csv(os.path.join(path, 'importances_72h_ed_revisit_disposition.csv'))\n",
    "importance_df.sort_values(by='Importance', axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
